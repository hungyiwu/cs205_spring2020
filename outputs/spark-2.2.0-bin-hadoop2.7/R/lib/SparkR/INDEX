$                       Select
%in%                    Match a column with given values.
AFTSurvivalRegressionModel-class
                        S4 class that represents a
                        AFTSurvivalRegressionModel
ALSModel-class          S4 class that represents an ALSModel
BisectingKMeansModel-class
                        S4 class that represents a BisectingKMeansModel
Column-class            S4 class that represents a SparkDataFrame
                        column
FPGrowthModel-class     S4 class that represents a FPGrowthModel
GBTClassificationModel-class
                        S4 class that represents a
                        GBTClassificationModel
GBTRegressionModel-class
                        S4 class that represents a GBTRegressionModel
GaussianMixtureModel-class
                        S4 class that represents a GaussianMixtureModel
GeneralizedLinearRegressionModel-class
                        S4 class that represents a generalized linear
                        model
GroupedData-class       S4 class that represents a GroupedData
IsotonicRegressionModel-class
                        S4 class that represents an
                        IsotonicRegressionModel
KMeansModel-class       S4 class that represents a KMeansModel
KSTest-class            S4 class that represents an KSTest
LDAModel-class          S4 class that represents an LDAModel
LinearSVCModel-class    S4 class that represents an LinearSVCModel
LogisticRegressionModel-class
                        S4 class that represents an
                        LogisticRegressionModel
MultilayerPerceptronClassificationModel-class
                        S4 class that represents a
                        MultilayerPerceptronClassificationModel
NaiveBayesModel-class   S4 class that represents a NaiveBayesModel
RandomForestClassificationModel-class
                        S4 class that represents a
                        RandomForestClassificationModel
RandomForestRegressionModel-class
                        S4 class that represents a
                        RandomForestRegressionModel
SparkDataFrame-class    S4 class that represents a SparkDataFrame
StreamingQuery-class    S4 class that represents a StreamingQuery
WindowSpec-class        S4 class that represents a WindowSpec
[[                      Subset
abs                     abs
acos                    acos
add_months              add_months
agg                     Summarize data across columns
alias                   alias
approxCountDistinct     Returns the approximate number of distinct
                        items in a group
approxQuantile          Calculates the approximate quantiles of
                        numerical columns of a SparkDataFrame
arrange                 Arrange Rows by Variables
array_contains          array_contains
as.data.frame,SparkDataFrame-method
                        Download data from a SparkDataFrame into a R
                        data.frame
ascii                   ascii
asin                    asin
atan                    atan
atan2                   atan2
attach,SparkDataFrame-method
                        Attach SparkDataFrame to R search path
avg                     avg
awaitTermination        awaitTermination
base64                  base64
between                 between
bin                     bin
bitwiseNOT              bitwiseNOT
bround                  bround
cache                   Cache
cacheTable              Cache Table
cancelJobGroup          Cancel active jobs for the specified group
cast                    Casts the column to a different data type.
cbrt                    cbrt
ceil                    Computes the ceiling of the given value
checkpoint              checkpoint
clearCache              Clear Cache
clearJobGroup           Clear current job group ID and its description
coalesce                Coalesce
collect                 Collects all the elements of a SparkDataFrame
                        and coerces them into an R data.frame.
coltypes                coltypes
columnfunctions         A set of operations working with SparkDataFrame
                        columns
columns                 Column Names of SparkDataFrame
concat                  concat
concat_ws               concat_ws
conv                    conv
corr                    corr
cos                     cos
cosh                    cosh
count                   Returns the number of items in a group
countDistinct           Count Distinct Values
cov                     cov
covar_pop               covar_pop
crc32                   crc32
createDataFrame         Create a SparkDataFrame
createExternalTable     (Deprecated) Create an external table
createOrReplaceTempView
                        Creates a temporary view using the given name.
createTable             Creates a table based on the dataset in a data
                        source
crossJoin               CrossJoin
crosstab                Computes a pair-wise frequency table of the
                        given columns
cume_dist               cume_dist
currentDatabase         Returns the current default database
dapply                  dapply
dapplyCollect           dapplyCollect
date_add                date_add
date_format             date_format
date_sub                date_sub
datediff                datediff
dayofmonth              dayofmonth
dayofyear               dayofyear
decode                  decode
dense_rank              dense_rank
describe                summary
dim                     Returns the dimensions of SparkDataFrame
distinct                Distinct
drop                    drop
dropDuplicates          dropDuplicates
dropTempTable           (Deprecated) Drop Temporary Table
dropTempView            Drops the temporary view with the given view
                        name in the catalog.
dropna                  A set of SparkDataFrame functions working with
                        NA values
dtypes                  DataTypes
encode                  encode
endsWith                endsWith
except                  except
exp                     exp
explain                 Explain
explode                 explode
expm1                   expm1
expr                    expr
factorial               factorial
filter                  Filter
first                   Return the first row of a SparkDataFrame
fitted                  Get fitted result from a k-means model
floor                   floor
format_number           format_number
format_string           format_string
freqItems               Finding frequent items for columns, possibly
                        with false positives
from_json               from_json
from_unixtime           from_unixtime
from_utc_timestamp      from_utc_timestamp
gapply                  gapply
gapplyCollect           gapplyCollect
generateAliasesForIntersectedCols
                        Creates a list of columns by replacing the
                        intersected ones with aliases
getNumPartitions        getNumPartitions
glm                     Generalized Linear Models (R-compliant)
greatest                greatest
groupBy                 GroupBy
hash                    hash
hashCode                Compute the hashCode of an object
head                    Head
hex                     hex
hint                    hint
histogram               Compute histogram statistics for given column
hour                    hour
hypot                   hypot
ifelse                  ifelse
initcap                 initcap
insertInto              insertInto
install.spark           Download and Install Apache Spark to a Local
                        Directory
instr                   instr
intersect               Intersect
is.nan                  is.nan
isActive                isActive
isLocal                 isLocal
isStreaming             isStreaming
join                    Join
kurtosis                kurtosis
lag                     lag
last                    last
lastProgress            lastProgress
last_day                last_day
lead                    lead
least                   least
length                  length
levenshtein             levenshtein
limit                   Limit
listColumns             Returns a list of columns for the given
                        table/view in the specified database
listDatabases           Returns a list of databases available
listFunctions           Returns a list of functions registered in the
                        specified database
listTables              Returns a list of tables or views in the
                        specified database
lit                     lit
locate                  locate
log                     log
log10                   log10
log1p                   log1p
log2                    log2
lower                   lower
lpad                    lpad
ltrim                   ltrim
max                     max
md5                     md5
mean                    mean
merge                   Merges two data frames
min                     min
minute                  minute
monotonically_increasing_id
                        monotonically_increasing_id
month                   month
months_between          months_between
mutate                  Mutate
nanvl                   nanvl
ncol                    Returns the number of columns in a
                        SparkDataFrame
negate                  negate
next_day                next_day
nrow                    Returns the number of rows in a SparkDataFrame
ntile                   ntile
orderBy                 Ordering Columns in a WindowSpec
otherwise               otherwise
over                    over
partitionBy             partitionBy
percent_rank            percent_rank
persist                 Persist
pivot                   Pivot a column of the GroupedData and perform
                        the specified aggregation.
pmod                    pmod
posexplode              posexplode
predict                 Makes predictions from a MLlib model
print.jobj              Print a JVM object reference.
print.structField       Print a Spark StructField.
print.structType        Print a Spark StructType.
printSchema             Print Schema of a SparkDataFrame
quarter                 quarter
queryName               queryName
rand                    rand
randn                   randn
randomSplit             randomSplit
rangeBetween            rangeBetween
rank                    rank
rbind                   Union two or more SparkDataFrames
read.df                 Load a SparkDataFrame
read.jdbc               Create a SparkDataFrame representing the
                        database table accessible via JDBC URL
read.json               Create a SparkDataFrame from a JSON file.
read.ml                 Load a fitted MLlib model from the input path.
read.orc                Create a SparkDataFrame from an ORC file.
read.parquet            Create a SparkDataFrame from a Parquet file.
read.stream             Load a streaming SparkDataFrame
read.text               Create a SparkDataFrame from a text file.
recoverPartitions       Recovers all the partitions in the directory of
                        a table and update the catalog
refreshByPath           Invalidates and refreshes all the cached data
                        and metadata for SparkDataFrame containing path
refreshTable            Invalidates and refreshes all the cached data
                        and metadata of the given table
regexp_extract          regexp_extract
regexp_replace          regexp_replace
registerTempTable       (Deprecated) Register Temporary Table
repartition             Repartition
reverse                 reverse
rint                    rint
round                   round
row_number              row_number
rowsBetween             rowsBetween
rpad                    rpad
rtrim                   rtrim
sample                  Sample
sampleBy                Returns a stratified sample without replacement
saveAsTable             Save the contents of the SparkDataFrame to a
                        data source as a table
schema                  Get schema object
sd                      sd
second                  second
selectExpr              SelectExpr
setCheckpointDir        Set checkpoint directory
setCurrentDatabase      Sets the current default database
setJobGroup             Assigns a group ID to all the jobs started by
                        this thread until the group ID is set to a
                        different value or cleared.
setLogLevel             Set new log level
sha1                    sha1
sha2                    sha2
shiftLeft               shiftLeft
shiftRight              shiftRight
shiftRightUnsigned      shiftRightUnsigned
show                    show
showDF                  showDF
signum                  signum
sin                     sin
sinh                    sinh
size                    size
skewness                skewness
sort_array              sort_array
soundex                 soundex
spark.addFile           Add a file or directory to be downloaded with
                        this Spark job on every node.
spark.als               Alternating Least Squares (ALS) for
                        Collaborative Filtering
spark.bisectingKmeans   Bisecting K-Means Clustering Model
spark.fpGrowth          FP-growth
spark.gaussianMixture   Multivariate Gaussian Mixture Model (GMM)
spark.gbt               Gradient Boosted Tree Model for Regression and
                        Classification
spark.getSparkFiles     Get the absolute path of a file added through
                        spark.addFile.
spark.getSparkFilesRootDirectory
                        Get the root directory that contains files
                        added through spark.addFile.
spark.glm               Generalized Linear Models
spark.isoreg            Isotonic Regression Model
spark.kmeans            K-Means Clustering Model
spark.kstest            (One-Sample) Kolmogorov-Smirnov Test
spark.lapply            Run a function over a list of elements,
                        distributing the computations with Spark
spark.lda               Latent Dirichlet Allocation
spark.logit             Logistic Regression Model
spark.mlp               Multilayer Perceptron Classification Model
spark.naiveBayes        Naive Bayes Models
spark.randomForest      Random Forest Model for Regression and
                        Classification
spark.survreg           Accelerated Failure Time (AFT) Survival
                        Regression Model
spark.svmLinear         Linear SVM Model
sparkR.callJMethod      Call Java Methods
sparkR.callJStatic      Call Static Java Methods
sparkR.conf             Get Runtime Config from the current active
                        SparkSession
sparkR.init             (Deprecated) Initialize a new Spark Context
sparkR.newJObject       Create Java Objects
sparkR.session          Get the existing SparkSession or initialize a
                        new SparkSession.
sparkR.session.stop     Stop the Spark Session and Spark Context
sparkR.uiWebUrl         Get the URL of the SparkUI instance for the
                        current active SparkSession
sparkR.version          Get version of Spark on which this application
                        is running
sparkRHive.init         (Deprecated) Initialize a new HiveContext
sparkRSQL.init          (Deprecated) Initialize a new SQLContext
spark_partition_id      Return the partition ID as a column
sql                     SQL Query
sqrt                    sqrt
startsWith              startsWith
status                  status
stddev_pop              stddev_pop
stddev_samp             stddev_samp
stopQuery               stopQuery
storageLevel            StorageLevel
str                     Compactly display the structure of a dataset
struct                  struct
structField             structField
structType              structType
substr                  substr
substring_index         substring_index
sum                     sum
sumDistinct             sumDistinct
tableNames              Table Names
tableToDF               Create a SparkDataFrame from a SparkSQL table
                        or view
tables                  Tables
take                    Take the first NUM rows of a SparkDataFrame and
                        return the results as a R data.frame
tan                     tan
tanh                    tanh
toDegrees               toDegrees
toJSON                  toJSON
toRadians               toRadians
to_date                 to_date
to_json                 to_json
to_timestamp            to_timestamp
to_utc_timestamp        to_utc_timestamp
translate               translate
trim                    trim
unbase64                unbase64
uncacheTable            Uncache Table
unhex                   unhex
union                   Return a new SparkDataFrame containing the
                        union of rows
unix_timestamp          unix_timestamp
unpersist               Unpersist
upper                   upper
var                     var
var_pop                 var_pop
var_samp                var_samp
weekofyear              weekofyear
when                    when
window                  window
windowOrderBy           windowOrderBy
windowPartitionBy       windowPartitionBy
with,SparkDataFrame-method
                        Evaluate a R expression in an environment
                        constructed from a SparkDataFrame
withColumn              WithColumn
withColumnRenamed       rename
write.df                Save the contents of SparkDataFrame to a data
                        source.
write.jdbc              Save the content of SparkDataFrame to an
                        external database table via JDBC.
write.json              Save the contents of SparkDataFrame as a JSON
                        file
write.ml                Saves the MLlib model to the input path
write.orc               Save the contents of SparkDataFrame as an ORC
                        file, preserving the schema.
write.parquet           Save the contents of SparkDataFrame as a
                        Parquet file, preserving the schema.
write.stream            Write the streaming SparkDataFrame to a data
                        source.
write.text              Save the content of SparkDataFrame in a text
                        file at the specified path.
year                    year
